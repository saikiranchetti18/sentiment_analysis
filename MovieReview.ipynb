{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MovieReview_SentimentClassification.ipynb",
      "provenance": [],
      "mount_file_id": "1fGyUDy5rFlahLCXA5eRTn5aKn0rKcmBp",
      "authorship_tag": "ABX9TyNKfE4wwUtMJlrhkYCMmwrx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saikiranchetti18/sentiment_analysis/blob/main/MovieReview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlsIhn8Jx1qk"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import re    \n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense \n",
        "from tensorflow.keras.models import load_model \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint  \n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IzZb9TV3L_KP",
        "outputId": "779b638c-95bd-4aa7-8c51-a49bc496f3f8"
      },
      "source": [
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/IMDB Dataset.csv')\n",
        "data.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY8Px_vwMaWe",
        "outputId": "9195d7dd-be03-483c-a53a-2f299e276997"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "english_stops =set(stopwords.words('english'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqkKehfuMdUN"
      },
      "source": [
        "def load_dataset():\n",
        "    df = pd.read_csv('/content/drive/MyDrive/IMDB Dataset.csv')\n",
        "    x_data = df['review']      \n",
        "    y_data = df['sentiment']  \n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex = True)         \n",
        "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)   \n",
        "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  \n",
        "    x_data = x_data.apply(lambda review: [w.lower() for w in review])\n",
        "    y_data = y_data.replace('positive', 1)\n",
        "    y_data = y_data.replace('negative', 0)\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "x_data, y_data = load_dataset()\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoM4Hy3wMhYE"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj-ZiOdgMm_J"
      },
      "source": [
        "def get_max_length():\n",
        "    length_reviews= []\n",
        "    for review in x_train:\n",
        "        length_reviews.append(len(review))\n",
        "    return int(np.ceil(np.mean(length_reviews)))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6d3-SSyMqAb",
        "outputId": "4caea16c-426f-4f3f-e039-ac38607d4e95"
      },
      "source": [
        "\n",
        "token = Tokenizer(lower=False)    \n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1 \n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded X Train\n",
            " [[1088  278    8 ...    0    0    0]\n",
            " [   8    3   21 ...    0    0    0]\n",
            " [  39   21 2027 ...    0    0    0]\n",
            " ...\n",
            " [ 611 1745   69 ...    0    0    0]\n",
            " [   2 1691 1220 ...    0    0    0]\n",
            " [ 499  315    3 ...    0    0    0]] \n",
            "\n",
            "Encoded X Test\n",
            " [[2251  616   70 ...    0    0    0]\n",
            " [   2  615 7015 ...    0    0    0]\n",
            " [   8 1153 2528 ...    0    0    0]\n",
            " ...\n",
            " [3624   23  878 ...    0    0    0]\n",
            " [ 394 1457  965 ...    0    0    0]\n",
            " [ 204   92    9 ... 1845  148  123]] \n",
            "\n",
            "Maximum review length:  130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkMqcsXOMtw0",
        "outputId": "7f8db2a7-59a3-4fbd-b659-fc8086b3648a"
      },
      "source": [
        "\n",
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
        "model.add(LSTM(LSTM_OUT)) \n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 130, 32)           2944800   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,969,697\n",
            "Trainable params: 2,969,697\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ6r8N1_MysH"
      },
      "source": [
        "checkpoint = ModelCheckpoint('models/LSTM.h5',monitor='accuracy',save_best_only=True,verbose=1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-HCySK_M10E",
        "outputId": "500098ba-c35f-4fd5-9106-268b081a61d9"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size = 128, epochs =10, callbacks=[checkpoint])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 65s 200ms/step - loss: 0.4753 - accuracy: 0.7424\n",
            "\n",
            "Epoch 00001: accuracy improved from -inf to 0.74240, saving model to models/LSTM.h5\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 62s 199ms/step - loss: 0.2121 - accuracy: 0.9247\n",
            "\n",
            "Epoch 00002: accuracy improved from 0.74240 to 0.92475, saving model to models/LSTM.h5\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 66s 211ms/step - loss: 0.1218 - accuracy: 0.9614\n",
            "\n",
            "Epoch 00003: accuracy improved from 0.92475 to 0.96145, saving model to models/LSTM.h5\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 64s 206ms/step - loss: 0.0764 - accuracy: 0.9780\n",
            "\n",
            "Epoch 00004: accuracy improved from 0.96145 to 0.97798, saving model to models/LSTM.h5\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 64s 204ms/step - loss: 0.0504 - accuracy: 0.9859\n",
            "\n",
            "Epoch 00005: accuracy improved from 0.97798 to 0.98595, saving model to models/LSTM.h5\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 61s 194ms/step - loss: 0.0384 - accuracy: 0.9898\n",
            "\n",
            "Epoch 00006: accuracy improved from 0.98595 to 0.98985, saving model to models/LSTM.h5\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 65s 209ms/step - loss: 0.0629 - accuracy: 0.9832\n",
            "\n",
            "Epoch 00007: accuracy did not improve from 0.98985\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 65s 208ms/step - loss: 0.0389 - accuracy: 0.9898\n",
            "\n",
            "Epoch 00008: accuracy did not improve from 0.98985\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 63s 201ms/step - loss: 0.0334 - accuracy: 0.9914\n",
            "\n",
            "Epoch 00009: accuracy improved from 0.98985 to 0.99142, saving model to models/LSTM.h5\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 63s 202ms/step - loss: 0.0310 - accuracy: 0.9924\n",
            "\n",
            "Epoch 00010: accuracy improved from 0.99142 to 0.99238, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f10ba782790>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frX1qeLYM5Gx",
        "outputId": "91d02bc6-01b3-4cda-d98c-fc686bc946e6"
      },
      "source": [
        "\n",
        "predict_x=model.predict(x_test) \n",
        "y_pred=np.argmax(predict_x,axis=1)\n",
        "true = 0\n",
        "for i, y in enumerate(y_test):\n",
        "    if y == y_pred[i]:\n",
        "        true += 1\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct Prediction: 5007\n",
            "Wrong Prediction: 4993\n",
            "Accuracy: 50.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD-aq8xsM8uM"
      },
      "source": [
        "loaded_model = load_model('models/LSTM.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3HA0NBNNEvO"
      },
      "source": [
        "def preprocess(review):\n",
        "    regex = re.compile(r'[^a-zA-Z\\s]')\n",
        "    review = regex.sub('', review)\n",
        "    print('Cleaned: ', review)\n",
        "\n",
        "    words = review.split(' ')\n",
        "    filtered = [w for w in words if w not in english_stops]\n",
        "    filtered = ' '.join(filtered)\n",
        "    filtered = [filtered.lower()]\n",
        "\n",
        "    print('Filtered: ', filtered)\n",
        "    tokenize_words = token.texts_to_sequences(filtered)\n",
        "    tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
        "    return (tokenize_words)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TqL6UaSNNGz",
        "outputId": "b7b73166-4fa7-48e9-e9f2-4d4737e7d45d"
      },
      "source": [
        "\n",
        "result=model.predict(preprocess(input()))\n",
        "print(result)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the movie is good\n",
            "Cleaned:  the movie is good\n",
            "Filtered:  ['movie good']\n",
            "[[0.9985483]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3R81PFoNOPP",
        "outputId": "a63a2d12-588f-45e1-b51e-d16241f12a76"
      },
      "source": [
        "print (\"positive_review\") if result>=0.6 else print(\"negative_review\")\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive_review\n"
          ]
        }
      ]
    }
  ]
}